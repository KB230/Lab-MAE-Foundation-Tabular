{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MAE import MaskedAutoencoder\n",
    "from torch import nn\n",
    "from functools import partial\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained model:\n",
    "\n",
    "The model is a Masked autoencoder model trained on MIMIC IV dataset using the 100 most common lab tests and its timestamps. The model was trained using the following parameters:\n",
    "\n",
    "- batch_size = 256\n",
    "- epochs = 500 with early stopping\n",
    "- dim=400 # 2 columns for each lab test: 200 + 200 for the corresponding timestamps = 400 in total\n",
    "- embed_dim=64\n",
    "- depth=8\n",
    "- decoder_depth=4\n",
    "- num_heads=8\n",
    "- mlp_ratio=4.0\n",
    "- norm_field_loss=False\n",
    "- encode_func='linear'\n",
    "- eps = 1e-7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns = df_test.shape[1] - 3 # + 3 because of: first_race, chartyear, hadm_id\n",
    "weigths = '100_Labs_Train_0.25Mask_L_V3/epoch390_checkpoint'\n",
    "device = 'cpu'\n",
    "\n",
    "batch_size=256 \n",
    "\n",
    "dim=400 # Columns\n",
    "embed_dim=64\n",
    "depth=8\n",
    "decoder_depth=4\n",
    "num_heads=8\n",
    "mlp_ratio=4.0\n",
    "norm_field_loss=False\n",
    "encode_func='linear'\n",
    "eps = 1e-7\n",
    "\n",
    "model = MaskedAutoencoder(\n",
    "    rec_len=dim,\n",
    "    embed_dim=embed_dim,\n",
    "    depth=depth,\n",
    "    num_heads=num_heads,\n",
    "    decoder_embed_dim=embed_dim,\n",
    "    decoder_depth=decoder_depth,\n",
    "    decoder_num_heads=num_heads,\n",
    "    mlp_ratio=mlp_ratio,\n",
    "    norm_layer=partial(nn.LayerNorm, eps=eps),\n",
    "    norm_field_loss=norm_field_loss,\n",
    "    encode_func=encode_func\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load(weigths, map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create some demo data to test the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor with the data shape (batch_size=2, columns=400)\n",
    "X = pd.DataFrame([[np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], \n",
    "                  [0.5, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   0.5, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,\n",
    "                   np.nan, 0.5, np.nan, 0.8, 0.3, 0.4, 0.5 ,0.6, 0.7, 0.8, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                  ])\n",
    "\n",
    "# Convert the dataframe to a tensor\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "\n",
    "# Create a mask tensor indicating which values are missing\n",
    "M = 1 - (1 * (np.isnan(X)))\n",
    "\n",
    "# Convert the nan values to 0 to avoid errors\n",
    "X = torch.nan_to_num(X)\n",
    "# Add a dimension to the tensor to match the model input\n",
    "X = X.unsqueeze(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 400]), torch.Size([2, 400]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, M.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of forward pass:\n",
    "\n",
    "Forward pass is done by calling the model with the input data. The model returns the a tuple with: loss, predictions, mask, nask.\n",
    "\n",
    "Inputs:\n",
    "- `X`: input data\n",
    "- `M`: mask indicating the valid positions in the input data (1 for valid positions, 0 for invalid positions). Invalid positions are missing data that should be predicted by the model.\n",
    "- `mask_ratio`: ratio of the values to be masked by the MAE model\n",
    "\n",
    "Outputs:\n",
    "- `loss`: loss value\n",
    "- `predictions`: predicted values\n",
    "- `mask`: mask indicating the valid positions in the input data\n",
    "- `nask`: mask indicating the invalid positions in the input\n",
    "\n",
    "Note: \n",
    "During inference set `mask_ratio` to 0.0 and use only the second element of the tuple (`predictions`) as the output.\n",
    "During training set `mask_ratio` to a value between 0.0 and 1.0 and use the first element of the tuple (`loss`) for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0906, grad_fn=<AddBackward0>),\n",
       " tensor([[[0.6369],\n",
       "          [0.4887],\n",
       "          [0.1396],\n",
       "          [0.8042],\n",
       "          [0.2963],\n",
       "          [0.3945],\n",
       "          [0.5100],\n",
       "          [0.5971],\n",
       "          [0.6908],\n",
       "          [0.8001],\n",
       "          [0.9105],\n",
       "          [0.0924],\n",
       "          [0.1996],\n",
       "          [0.2921],\n",
       "          [0.4126],\n",
       "          [0.4954],\n",
       "          [0.6029],\n",
       "          [0.6395],\n",
       "          [0.8009],\n",
       "          [0.9011],\n",
       "          [0.5689],\n",
       "          [0.4984],\n",
       "          [0.4393],\n",
       "          [0.8064],\n",
       "          [0.8360],\n",
       "          [0.3935],\n",
       "          [0.5050],\n",
       "          [0.6009],\n",
       "          [0.7031],\n",
       "          [0.8045],\n",
       "          [0.8964],\n",
       "          [0.1040],\n",
       "          [0.2049],\n",
       "          [0.7541],\n",
       "          [0.4046],\n",
       "          [0.4938],\n",
       "          [0.5980],\n",
       "          [0.6933],\n",
       "          [0.7968],\n",
       "          [0.8991],\n",
       "          [0.3172],\n",
       "          [0.4958],\n",
       "          [0.3246],\n",
       "          [0.7988],\n",
       "          [0.3504],\n",
       "          [0.3882],\n",
       "          [0.4973],\n",
       "          [0.5988],\n",
       "          [0.6917],\n",
       "          [0.7883],\n",
       "          [0.8969],\n",
       "          [0.0978],\n",
       "          [0.2569],\n",
       "          [0.3020],\n",
       "          [0.4024],\n",
       "          [0.4951],\n",
       "          [0.6045],\n",
       "          [0.4785],\n",
       "          [0.8079],\n",
       "          [0.6145],\n",
       "          [0.6322],\n",
       "          [0.5003],\n",
       "          [0.2846],\n",
       "          [0.8057],\n",
       "          [0.3037],\n",
       "          [0.3913],\n",
       "          [0.5009],\n",
       "          [0.5991],\n",
       "          [0.6987],\n",
       "          [0.4185],\n",
       "          [0.8961],\n",
       "          [0.1017],\n",
       "          [0.1988],\n",
       "          [0.2892],\n",
       "          [0.4051],\n",
       "          [0.5046],\n",
       "          [0.5974],\n",
       "          [0.7045],\n",
       "          [0.7988],\n",
       "          [0.6300],\n",
       "          [0.3203],\n",
       "          [0.4886],\n",
       "          [0.8661],\n",
       "          [0.8042],\n",
       "          [0.2372],\n",
       "          [0.4003],\n",
       "          [0.7950],\n",
       "          [0.5970],\n",
       "          [0.6921],\n",
       "          [0.7921],\n",
       "          [0.9059],\n",
       "          [0.1044],\n",
       "          [0.2077],\n",
       "          [0.3796],\n",
       "          [0.4108],\n",
       "          [0.4932],\n",
       "          [0.6149],\n",
       "          [0.6915],\n",
       "          [0.7837],\n",
       "          [0.5315],\n",
       "          [0.7080],\n",
       "          [0.5274],\n",
       "          [0.5021],\n",
       "          [0.8056],\n",
       "          [0.3159],\n",
       "          [0.3979],\n",
       "          [0.4973],\n",
       "          [0.5977],\n",
       "          [0.5171],\n",
       "          [0.7959],\n",
       "          [0.8818],\n",
       "          [0.0889],\n",
       "          [0.1981],\n",
       "          [0.3038],\n",
       "          [0.7331],\n",
       "          [0.4998],\n",
       "          [0.2449],\n",
       "          [0.7016],\n",
       "          [0.7919],\n",
       "          [0.8991],\n",
       "          [0.2342],\n",
       "          [0.4994],\n",
       "          [0.8608],\n",
       "          [0.8053],\n",
       "          [0.2957],\n",
       "          [0.5957],\n",
       "          [0.5016],\n",
       "          [0.5972],\n",
       "          [0.6994],\n",
       "          [0.8003],\n",
       "          [0.8958],\n",
       "          [0.0894],\n",
       "          [0.2038],\n",
       "          [0.2916],\n",
       "          [0.4279],\n",
       "          [0.5051],\n",
       "          [0.4225],\n",
       "          [0.7063],\n",
       "          [0.7970],\n",
       "          [0.4908],\n",
       "          [0.3979],\n",
       "          [0.4963],\n",
       "          [0.3267],\n",
       "          [0.4245],\n",
       "          [0.3003],\n",
       "          [0.3926],\n",
       "          [0.4823],\n",
       "          [0.6131],\n",
       "          [0.6928],\n",
       "          [0.8001],\n",
       "          [0.8858],\n",
       "          [0.6017],\n",
       "          [0.1902],\n",
       "          [0.4307],\n",
       "          [0.4505],\n",
       "          [0.5073],\n",
       "          [0.5052],\n",
       "          [0.6358],\n",
       "          [0.7987],\n",
       "          [0.8962],\n",
       "          [0.3824],\n",
       "          [0.5057],\n",
       "          [0.2997],\n",
       "          [0.8098],\n",
       "          [0.2966],\n",
       "          [0.5921],\n",
       "          [0.5132],\n",
       "          [0.4118],\n",
       "          [0.6816],\n",
       "          [0.7952],\n",
       "          [0.9149],\n",
       "          [0.0962],\n",
       "          [0.2026],\n",
       "          [0.2894],\n",
       "          [0.4023],\n",
       "          [0.4997],\n",
       "          [0.5970],\n",
       "          [0.7023],\n",
       "          [0.7946],\n",
       "          [0.8946],\n",
       "          [0.4930],\n",
       "          [0.4872],\n",
       "          [0.4996],\n",
       "          [0.4815],\n",
       "          [0.2892],\n",
       "          [0.3948],\n",
       "          [0.4935],\n",
       "          [0.5786],\n",
       "          [0.6913],\n",
       "          [0.7969],\n",
       "          [0.8850],\n",
       "          [0.0992],\n",
       "          [0.1999],\n",
       "          [0.2940],\n",
       "          [0.3944],\n",
       "          [0.5042],\n",
       "          [0.5994],\n",
       "          [0.7018],\n",
       "          [0.7879],\n",
       "          [0.9122],\n",
       "          [0.5526],\n",
       "          [0.4942],\n",
       "          [0.1925],\n",
       "          [0.8042],\n",
       "          [0.2940],\n",
       "          [0.5894],\n",
       "          [0.4378],\n",
       "          [0.5746],\n",
       "          [0.6889],\n",
       "          [0.8076],\n",
       "          [0.9050],\n",
       "          [0.1056],\n",
       "          [0.2035],\n",
       "          [0.6155],\n",
       "          [0.4155],\n",
       "          [0.4903],\n",
       "          [0.6016],\n",
       "          [0.6976],\n",
       "          [0.8017],\n",
       "          [0.4920],\n",
       "          [0.4057],\n",
       "          [0.4970],\n",
       "          [0.4609],\n",
       "          [0.7979],\n",
       "          [0.3042],\n",
       "          [0.4067],\n",
       "          [0.4135],\n",
       "          [0.6085],\n",
       "          [0.6961],\n",
       "          [0.8123],\n",
       "          [0.5878],\n",
       "          [0.0987],\n",
       "          [0.2056],\n",
       "          [0.5591],\n",
       "          [0.6641],\n",
       "          [0.4895],\n",
       "          [0.5903],\n",
       "          [0.6904],\n",
       "          [0.8037],\n",
       "          [0.8954],\n",
       "          [0.2681],\n",
       "          [0.4904],\n",
       "          [0.3197],\n",
       "          [0.4324],\n",
       "          [0.2963],\n",
       "          [0.3905],\n",
       "          [0.4941],\n",
       "          [0.5923],\n",
       "          [0.6926],\n",
       "          [0.2601],\n",
       "          [0.2711],\n",
       "          [0.0939],\n",
       "          [0.1920],\n",
       "          [0.3015],\n",
       "          [0.4035],\n",
       "          [0.6327],\n",
       "          [0.6133],\n",
       "          [0.6892],\n",
       "          [0.0790],\n",
       "          [0.8951],\n",
       "          [0.6480],\n",
       "          [0.5068],\n",
       "          [0.3429],\n",
       "          [0.7808],\n",
       "          [0.1534],\n",
       "          [0.3996],\n",
       "          [0.5038],\n",
       "          [0.5876],\n",
       "          [0.7049],\n",
       "          [0.7940],\n",
       "          [0.8906],\n",
       "          [0.1051],\n",
       "          [0.1965],\n",
       "          [0.3026],\n",
       "          [0.4165],\n",
       "          [0.4999],\n",
       "          [0.8992],\n",
       "          [0.6933],\n",
       "          [0.7991],\n",
       "          [0.9141],\n",
       "          [0.2803],\n",
       "          [0.4970],\n",
       "          [0.2206],\n",
       "          [0.7849],\n",
       "          [0.2942],\n",
       "          [0.3976],\n",
       "          [0.5041],\n",
       "          [0.5951],\n",
       "          [0.6819],\n",
       "          [0.8028],\n",
       "          [0.8928],\n",
       "          [0.8266],\n",
       "          [0.2042],\n",
       "          [0.7574],\n",
       "          [0.4042],\n",
       "          [0.4837],\n",
       "          [0.5892],\n",
       "          [0.7030],\n",
       "          [0.7913],\n",
       "          [0.4966],\n",
       "          [0.5025],\n",
       "          [0.7732],\n",
       "          [0.3106],\n",
       "          [0.8089],\n",
       "          [0.1287],\n",
       "          [0.4091],\n",
       "          [0.5102],\n",
       "          [0.6014],\n",
       "          [0.3997],\n",
       "          [0.7989],\n",
       "          [0.8033],\n",
       "          [0.0961],\n",
       "          [0.2054],\n",
       "          [0.2876],\n",
       "          [0.3980],\n",
       "          [0.4947],\n",
       "          [0.1060],\n",
       "          [0.6886],\n",
       "          [0.8049],\n",
       "          [0.9098],\n",
       "          [0.1342],\n",
       "          [0.4964],\n",
       "          [0.7498],\n",
       "          [0.8065],\n",
       "          [0.3120],\n",
       "          [0.4111],\n",
       "          [0.4980],\n",
       "          [0.5930],\n",
       "          [0.3981],\n",
       "          [0.8189],\n",
       "          [0.7673],\n",
       "          [0.5368],\n",
       "          [0.2080],\n",
       "          [0.3148],\n",
       "          [0.3965],\n",
       "          [0.4995],\n",
       "          [0.5906],\n",
       "          [0.6981],\n",
       "          [0.8033],\n",
       "          [0.1769],\n",
       "          [0.3654],\n",
       "          [0.6946],\n",
       "          [0.4050],\n",
       "          [0.8071],\n",
       "          [0.3022],\n",
       "          [0.3672],\n",
       "          [0.4982],\n",
       "          [0.6004],\n",
       "          [0.6964],\n",
       "          [0.7974],\n",
       "          [0.2461],\n",
       "          [0.1002],\n",
       "          [0.3219],\n",
       "          [0.2971],\n",
       "          [0.4097],\n",
       "          [0.3574],\n",
       "          [0.5952],\n",
       "          [0.6991],\n",
       "          [0.7888],\n",
       "          [0.8948],\n",
       "          [0.3310],\n",
       "          [0.5054],\n",
       "          [0.1006],\n",
       "          [0.8123],\n",
       "          [0.2970],\n",
       "          [0.6098],\n",
       "          [0.5018],\n",
       "          [0.6118],\n",
       "          [0.6967],\n",
       "          [0.7983],\n",
       "          [0.7816],\n",
       "          [0.0904],\n",
       "          [0.1055],\n",
       "          [0.6097],\n",
       "          [0.3972],\n",
       "          [0.5001],\n",
       "          [0.7657],\n",
       "          [0.7023],\n",
       "          [0.8061],\n",
       "          [0.8717],\n",
       "          [0.8485],\n",
       "          [0.4971],\n",
       "          [0.3076],\n",
       "          [0.7827],\n",
       "          [0.2975],\n",
       "          [0.8501],\n",
       "          [0.4980],\n",
       "          [0.5931],\n",
       "          [0.4311],\n",
       "          [0.7966],\n",
       "          [0.8560],\n",
       "          [0.6951],\n",
       "          [0.1871],\n",
       "          [0.2816],\n",
       "          [0.3892],\n",
       "          [0.7489],\n",
       "          [0.5027],\n",
       "          [0.6887],\n",
       "          [0.7565],\n",
       "          [0.9159]],\n",
       " \n",
       "         [[0.5704],\n",
       "          [0.4914],\n",
       "          [0.2439],\n",
       "          [0.8048],\n",
       "          [0.2976],\n",
       "          [0.3939],\n",
       "          [0.5046],\n",
       "          [0.5962],\n",
       "          [0.6968],\n",
       "          [0.8004],\n",
       "          [0.9072],\n",
       "          [0.0929],\n",
       "          [0.2012],\n",
       "          [0.2950],\n",
       "          [0.4208],\n",
       "          [0.4965],\n",
       "          [0.6079],\n",
       "          [0.6928],\n",
       "          [0.8028],\n",
       "          [0.3713],\n",
       "          [0.4840],\n",
       "          [0.3395],\n",
       "          [0.5446],\n",
       "          [0.8062],\n",
       "          [0.2984],\n",
       "          [0.3934],\n",
       "          [0.5005],\n",
       "          [0.5998],\n",
       "          [0.9605],\n",
       "          [0.8046],\n",
       "          [0.8129],\n",
       "          [0.1052],\n",
       "          [0.2036],\n",
       "          [0.2966],\n",
       "          [0.4036],\n",
       "          [0.4926],\n",
       "          [0.5930],\n",
       "          [0.6896],\n",
       "          [0.7962],\n",
       "          [0.8948],\n",
       "          [0.4176],\n",
       "          [0.4938],\n",
       "          [0.2981],\n",
       "          [0.7994],\n",
       "          [0.2960],\n",
       "          [0.3929],\n",
       "          [0.5029],\n",
       "          [0.5961],\n",
       "          [0.6908],\n",
       "          [0.7650],\n",
       "          [0.3996],\n",
       "          [0.1008],\n",
       "          [0.2463],\n",
       "          [0.3149],\n",
       "          [0.4051],\n",
       "          [0.4980],\n",
       "          [0.6058],\n",
       "          [0.6988],\n",
       "          [0.8085],\n",
       "          [0.9066],\n",
       "          [0.5575],\n",
       "          [0.7504],\n",
       "          [0.7110],\n",
       "          [0.8053],\n",
       "          [0.3003],\n",
       "          [0.6165],\n",
       "          [0.4948],\n",
       "          [0.5972],\n",
       "          [0.3650],\n",
       "          [0.8056],\n",
       "          [0.3094],\n",
       "          [0.1012],\n",
       "          [0.1946],\n",
       "          [0.2879],\n",
       "          [0.4046],\n",
       "          [0.5040],\n",
       "          [0.5957],\n",
       "          [0.7021],\n",
       "          [0.7977],\n",
       "          [0.9094],\n",
       "          [0.3530],\n",
       "          [0.8293],\n",
       "          [0.8349],\n",
       "          [0.8048],\n",
       "          [0.1963],\n",
       "          [0.4002],\n",
       "          [0.6216],\n",
       "          [0.5918],\n",
       "          [0.4057],\n",
       "          [0.7933],\n",
       "          [0.7145],\n",
       "          [0.1115],\n",
       "          [0.2047],\n",
       "          [0.3048],\n",
       "          [0.4158],\n",
       "          [0.4917],\n",
       "          [0.6092],\n",
       "          [0.6952],\n",
       "          [0.7836],\n",
       "          [0.9039],\n",
       "          [0.5724],\n",
       "          [0.5073],\n",
       "          [0.6569],\n",
       "          [0.8032],\n",
       "          [0.3068],\n",
       "          [0.3909],\n",
       "          [0.6790],\n",
       "          [0.5905],\n",
       "          [0.4390],\n",
       "          [0.7971],\n",
       "          [0.8779],\n",
       "          [0.0923],\n",
       "          [0.1998],\n",
       "          [0.2993],\n",
       "          [0.3955],\n",
       "          [0.5965],\n",
       "          [0.5911],\n",
       "          [0.6997],\n",
       "          [0.7988],\n",
       "          [0.6916],\n",
       "          [0.3411],\n",
       "          [0.4956],\n",
       "          [0.8798],\n",
       "          [0.8048],\n",
       "          [0.3013],\n",
       "          [0.3890],\n",
       "          [0.4993],\n",
       "          [0.5974],\n",
       "          [0.6995],\n",
       "          [0.6984],\n",
       "          [0.8965],\n",
       "          [0.0902],\n",
       "          [0.3904],\n",
       "          [0.2973],\n",
       "          [0.4057],\n",
       "          [0.5109],\n",
       "          [0.6041],\n",
       "          [0.7063],\n",
       "          [0.7993],\n",
       "          [0.9128],\n",
       "          [0.3636],\n",
       "          [0.7608],\n",
       "          [0.3585],\n",
       "          [0.8014],\n",
       "          [0.4682],\n",
       "          [0.3946],\n",
       "          [0.4814],\n",
       "          [0.6087],\n",
       "          [0.6967],\n",
       "          [0.8038],\n",
       "          [0.2469],\n",
       "          [0.1004],\n",
       "          [0.1904],\n",
       "          [0.2941],\n",
       "          [0.4439],\n",
       "          [0.5045],\n",
       "          [0.5175],\n",
       "          [0.7016],\n",
       "          [0.8024],\n",
       "          [0.5839],\n",
       "          [0.3845],\n",
       "          [0.3969],\n",
       "          [0.3797],\n",
       "          [0.8050],\n",
       "          [0.2473],\n",
       "          [0.3958],\n",
       "          [0.5143],\n",
       "          [0.6042],\n",
       "          [0.6811],\n",
       "          [0.7942],\n",
       "          [0.8897],\n",
       "          [0.0957],\n",
       "          [0.2030],\n",
       "          [0.4140],\n",
       "          [0.4040],\n",
       "          [0.5018],\n",
       "          [0.7098],\n",
       "          [0.6824],\n",
       "          [0.7962],\n",
       "          [0.8942],\n",
       "          [0.6230],\n",
       "          [0.8060],\n",
       "          [0.5702],\n",
       "          [0.7926],\n",
       "          [0.1247],\n",
       "          [0.3920],\n",
       "          [0.4957],\n",
       "          [0.5888],\n",
       "          [0.7000],\n",
       "          [0.7983],\n",
       "          [0.8892],\n",
       "          [0.1005],\n",
       "          [0.2070],\n",
       "          [0.4813],\n",
       "          [0.3953],\n",
       "          [0.6382],\n",
       "          [0.5963],\n",
       "          [0.7081],\n",
       "          [0.7827],\n",
       "          [0.9104],\n",
       "          [0.5460],\n",
       "          [0.4912],\n",
       "          [0.4451],\n",
       "          [0.8133],\n",
       "          [0.2988],\n",
       "          [0.3864],\n",
       "          [0.5218],\n",
       "          [0.5746],\n",
       "          [0.6848],\n",
       "          [0.3904],\n",
       "          [0.7878],\n",
       "          [0.0984],\n",
       "          [0.2048],\n",
       "          [0.2800],\n",
       "          [0.8061],\n",
       "          [0.4831],\n",
       "          [0.4520],\n",
       "          [0.4386],\n",
       "          [0.7981],\n",
       "          [0.8983],\n",
       "          [0.5573],\n",
       "          [0.4903],\n",
       "          [0.5063],\n",
       "          [0.7971],\n",
       "          [0.3027],\n",
       "          [0.4036],\n",
       "          [0.4905],\n",
       "          [0.6086],\n",
       "          [0.9839],\n",
       "          [0.8136],\n",
       "          [0.9007],\n",
       "          [0.0987],\n",
       "          [0.2010],\n",
       "          [0.2937],\n",
       "          [0.6451],\n",
       "          [0.5552],\n",
       "          [0.4575],\n",
       "          [0.6795],\n",
       "          [0.8009],\n",
       "          [0.6649],\n",
       "          [0.3444],\n",
       "          [0.6034],\n",
       "          [0.3136],\n",
       "          [0.8064],\n",
       "          [0.2965],\n",
       "          [0.3907],\n",
       "          [0.4968],\n",
       "          [0.5919],\n",
       "          [0.6947],\n",
       "          [0.7897],\n",
       "          [0.9006],\n",
       "          [0.1012],\n",
       "          [0.1917],\n",
       "          [0.3005],\n",
       "          [0.3809],\n",
       "          [0.5059],\n",
       "          [0.6156],\n",
       "          [0.6942],\n",
       "          [0.8012],\n",
       "          [0.8937],\n",
       "          [0.3550],\n",
       "          [0.5086],\n",
       "          [0.4977],\n",
       "          [0.5037],\n",
       "          [0.2985],\n",
       "          [0.4047],\n",
       "          [0.4987],\n",
       "          [0.5928],\n",
       "          [0.3519],\n",
       "          [0.7872],\n",
       "          [0.8906],\n",
       "          [0.1009],\n",
       "          [0.1950],\n",
       "          [0.3032],\n",
       "          [0.4249],\n",
       "          [0.5055],\n",
       "          [0.5973],\n",
       "          [0.6925],\n",
       "          [0.8015],\n",
       "          [0.7658],\n",
       "          [0.3135],\n",
       "          [0.4936],\n",
       "          [0.2052],\n",
       "          [0.7704],\n",
       "          [0.2947],\n",
       "          [0.4337],\n",
       "          [0.5012],\n",
       "          [0.5961],\n",
       "          [0.6769],\n",
       "          [0.8016],\n",
       "          [0.8963],\n",
       "          [0.7786],\n",
       "          [0.2069],\n",
       "          [0.3012],\n",
       "          [0.4055],\n",
       "          [0.4844],\n",
       "          [0.5874],\n",
       "          [0.7033],\n",
       "          [0.7865],\n",
       "          [0.8977],\n",
       "          [0.4844],\n",
       "          [0.4923],\n",
       "          [0.4085],\n",
       "          [0.8068],\n",
       "          [0.3008],\n",
       "          [0.4051],\n",
       "          [0.5053],\n",
       "          [0.5536],\n",
       "          [0.6598],\n",
       "          [0.7814],\n",
       "          [0.8118],\n",
       "          [0.0938],\n",
       "          [0.2062],\n",
       "          [0.2813],\n",
       "          [0.3994],\n",
       "          [0.6045],\n",
       "          [0.1087],\n",
       "          [0.6877],\n",
       "          [0.7969],\n",
       "          [0.6986],\n",
       "          [0.2359],\n",
       "          [0.4941],\n",
       "          [0.5497],\n",
       "          [0.8023],\n",
       "          [0.3131],\n",
       "          [0.4152],\n",
       "          [0.4960],\n",
       "          [0.5934],\n",
       "          [0.6896],\n",
       "          [0.8209],\n",
       "          [0.9048],\n",
       "          [0.5023],\n",
       "          [0.2074],\n",
       "          [0.3134],\n",
       "          [0.4006],\n",
       "          [0.5039],\n",
       "          [0.8728],\n",
       "          [0.7007],\n",
       "          [0.3293],\n",
       "          [0.8696],\n",
       "          [0.3183],\n",
       "          [0.4913],\n",
       "          [0.3803],\n",
       "          [0.7998],\n",
       "          [0.2985],\n",
       "          [0.3977],\n",
       "          [0.4983],\n",
       "          [0.6014],\n",
       "          [0.7006],\n",
       "          [0.7155],\n",
       "          [0.8691],\n",
       "          [0.0991],\n",
       "          [0.2003],\n",
       "          [0.2976],\n",
       "          [0.4085],\n",
       "          [0.5417],\n",
       "          [0.6003],\n",
       "          [0.7010],\n",
       "          [0.7920],\n",
       "          [0.8934],\n",
       "          [0.4122],\n",
       "          [0.5035],\n",
       "          [0.2861],\n",
       "          [0.8121],\n",
       "          [0.1550],\n",
       "          [0.4024],\n",
       "          [0.4799],\n",
       "          [0.6089],\n",
       "          [0.6892],\n",
       "          [0.7981],\n",
       "          [0.8676],\n",
       "          [0.4981],\n",
       "          [0.2027],\n",
       "          [0.3075],\n",
       "          [0.3307],\n",
       "          [0.5101],\n",
       "          [0.6111],\n",
       "          [0.7004],\n",
       "          [0.6805],\n",
       "          [0.6729],\n",
       "          [0.6558],\n",
       "          [0.4977],\n",
       "          [0.2753],\n",
       "          [0.4767],\n",
       "          [0.2962],\n",
       "          [0.8490],\n",
       "          [0.4940],\n",
       "          [0.5957],\n",
       "          [0.7167],\n",
       "          [0.8047],\n",
       "          [0.8662],\n",
       "          [0.1033],\n",
       "          [0.4669],\n",
       "          [0.2930],\n",
       "          [0.3888],\n",
       "          [0.5086],\n",
       "          [0.5939],\n",
       "          [0.5603],\n",
       "          [0.7400],\n",
       "          [0.9075]]], grad_fn=<SliceBackward0>),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "          1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "          0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "          1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 1., 0., 0.]]),\n",
       " tensor([[0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "          1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "          0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "          1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "          1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "          0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "          0., 1., 1., 1.],\n",
       "         [0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "          0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "          0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
       "          1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "          1., 0., 1., 1.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X, M, mask_ratio=0.2) # Output is a tuple with: loss, predictions, mask, nask\n",
    "# Note: during inference set mask_ratio=0.0 and only use the predictions tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embeddings:\n",
    "\n",
    "The model has a method to extract the embeddings of the input data. The method receives the input data and the mask and returns the embeddings of the valid positions and the embeddings of the cls token.\n",
    "\n",
    "Inputs:\n",
    "- `X`: input data\n",
    "- `M`: mask indicating the valid positions in the input data (1 for valid positions, 0 for invalid positions). Invalid positions are missing data that should be predicted by the model.\n",
    "- `mask_ratio` (optional): ratio of the values to be masked by the MAE model. Default is 0.0\n",
    "\n",
    "Outputs:\n",
    "- `embeddings`: embeddings of the valid positions in the input data. The shape is (batch_size, seq_len, emb_dim). the embeddings of the invalid positions are filled with np.nan values.\n",
    "- `cls_embeddings`: embeddings of the cls token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, cls_embedding = model.extract_embeddings(X, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 400, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         [-0.2416, -0.9443,  0.1086,  ..., -0.2403,  0.2612,  0.0051],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         ...,\n",
       "         [ 0.6908, -0.7115,  0.3388,  ...,  0.7217, -0.4952, -1.0635],\n",
       "         [-0.1543,  0.4914, -0.5550,  ..., -0.2721, -0.2909, -0.6287],\n",
       "         [-0.3792,  0.3128,  0.3379,  ...,  0.0617, -0.1295, -0.7110]],\n",
       "\n",
       "        [[-0.0360, -0.4197,  0.4760,  ...,  0.0408, -0.1766,  0.7799],\n",
       "         [-0.2475, -0.9181,  0.1032,  ..., -0.2477,  0.2731, -0.0031],\n",
       "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
       "         ...,\n",
       "         [ 0.6888, -0.7126,  0.3376,  ...,  0.7271, -0.4950, -1.0622],\n",
       "         [-0.1525,  0.4921, -0.5548,  ..., -0.2719, -0.2894, -0.6280],\n",
       "         [-0.3814,  0.3154,  0.3387,  ...,  0.0608, -0.1303, -0.7126]]],\n",
       "       grad_fn=<AsStridedBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5699e-02,  6.3364e-01, -6.0745e-01, -1.5556e-01, -1.0331e+00,\n",
       "         -1.2777e-01, -1.1509e+00, -9.4867e-01,  9.1756e-02,  1.4694e-01,\n",
       "         -1.7349e-01, -7.7522e-01, -5.2982e-01, -2.7562e-01,  6.0526e-01,\n",
       "         -7.7315e-01, -1.2642e-01,  9.6521e-01, -2.1740e-01, -3.2482e-01,\n",
       "         -1.2552e-01,  3.0561e-01,  6.3130e-02,  3.0150e-01,  2.7939e-01,\n",
       "          9.0490e-01,  9.1128e-01,  1.1288e-04,  5.6387e-01,  4.4801e-02,\n",
       "          1.0105e+00, -9.3561e-01, -1.2520e-01,  7.5231e-01,  3.1883e-02,\n",
       "         -1.4329e-01, -1.5316e-03, -5.2973e-01, -8.6476e-01,  3.1874e-01,\n",
       "         -1.0763e+00,  2.1091e-01, -2.4990e-02, -4.2509e-02,  1.2121e+00,\n",
       "          6.0505e-01, -5.7568e-01, -5.6585e-01, -2.0443e-01,  5.9395e-01,\n",
       "         -8.5318e-02,  5.3784e-01, -3.3979e-01,  7.5654e-02,  6.5231e-01,\n",
       "         -3.4830e-01, -6.5401e-02,  4.9329e-01, -9.7070e-01,  8.2891e-02,\n",
       "         -4.9702e-01,  6.9165e-01, -3.1891e-01, -1.7545e-01],\n",
       "        [ 2.1343e-02,  6.2828e-01, -6.0903e-01, -1.6183e-01, -1.0330e+00,\n",
       "         -1.2544e-01, -1.1532e+00, -9.5088e-01,  9.2002e-02,  1.4717e-01,\n",
       "         -1.6627e-01, -7.6859e-01, -5.4208e-01, -2.7962e-01,  6.0451e-01,\n",
       "         -7.7415e-01, -1.2813e-01,  9.7138e-01, -2.1857e-01, -3.2553e-01,\n",
       "         -1.2083e-01,  3.0690e-01,  6.3564e-02,  3.0629e-01,  2.7543e-01,\n",
       "          9.1098e-01,  9.1145e-01,  1.1318e-04,  5.6467e-01,  3.8746e-02,\n",
       "          1.0152e+00, -9.2121e-01, -1.2563e-01,  7.5013e-01,  2.3528e-02,\n",
       "         -1.4152e-01, -1.5343e-03, -5.3774e-01, -8.6900e-01,  3.1533e-01,\n",
       "         -1.0636e+00,  2.1279e-01, -2.6789e-02, -3.7787e-02,  1.2064e+00,\n",
       "          6.0779e-01, -5.7389e-01, -5.6245e-01, -2.0499e-01,  5.9112e-01,\n",
       "         -9.1253e-02,  5.3954e-01, -3.4667e-01,  6.4436e-02,  6.5740e-01,\n",
       "         -3.4507e-01, -6.3097e-02,  5.0197e-01, -9.6761e-01,  8.7376e-02,\n",
       "         -4.9357e-01,  6.9752e-01, -3.1866e-01, -1.7639e-01]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
